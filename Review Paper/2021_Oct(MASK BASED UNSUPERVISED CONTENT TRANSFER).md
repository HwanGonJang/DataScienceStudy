# 10월 논문리뷰
## 개요
GDSC Soongsil (Google Development Student Club), 숭실대학교의 GDSC 에서 제가 참여한 AI 파트는 매월 하나의 논문을 매주 리뷰하기로 했습니다. 10월 첫 논문 리뷰는 MASK BASED UNSUPERVISED CONTENT TRANSFER 라는 논문입니다.

## MASK BASED UNSUPERVISED CONTENT TRANSFER

### 0. Abstract

 이 논문은 마스크 기반 자율 콘텐츠 이동에 대한 논문이다. 이 논문에서는 비교적 더 많은 정보를 가지고 있는 도메인과  그렇지 않은 도메인 두 개를 이용하여 어떤 콘텐츠를 옮기는 문제를 해결한다. 제안하는 방법은 도메인의 공통적인 부분과 분리된 부분을 구분하여 마스크 생성을 통해 요구되는 향상에만 기본 네트워크를 집중한다. 이를 통해 광범위한 정향, 정성적 평가를 통해 입증된 것 처럼 최첨단의 질과 다양한 콘텐츠 이동이 가능하다. 이 방식은 다른 가이드 이미지와 도메인의 별도 콘텐츠를 추가할 수 있을 뿐만 아니라 기존의 별도 콘텐츠를 제거할 수도 있다. 더하여 클래스 라벨들만 제공되는 각 도메인에 대해 약한 지도적인 의미적인 분할을 가능하게 한다.

### 1. Introduction(논문 소개)

 본 논문에서는 새로운 분리 아이디어를 기반으로 하지만 계산에 사용되는 불필요한 자원과 매개변수의 사용을 최소화한다는 과제를 갖는다. 즉, 마스크를 사용하여 전체 대상에 대해 불필요한 재구성의 낭비를 요청하지 않고 원하는 증강에만 네트워크를 집중한다. 이 방법은 두 가지 주요 단계로 구성된다.

1. 첫번째 단계는 도메인의 특정 내용과 변하지 않는 콘텐츠를 별도로 인코딩 하는 단계이다.
2. 두번째 단계는 본 논문의 핵심 통찰로, 반드시 변해야할 타겟의 부분을 찾아내고 그것에 어울리는 증강 콘텐츠를 생성한다. 이렇게 하면 관련 없는 사항들을 그대로 유지할 수 있어 생성 품질을 크게 향상 시킬 수 있다. 증강은 관련있는 부분에 초점을 맞추며 (자동 인코더 유사 모듈의)병목 현상을 겪지 않고 대상 이미지에서 직접 다른 모든 세부 정보를 가져온다.

 이러한 논문의 방법은 또한 반대의 경우에도 사용할 수 있는데, 즉, 도메인별 속성을 제거하고 다시 원래대로 변환하는 것이다. 이 기능은 중심 기능이 아님에도 높은 능력을 갖고 있다. 이는 콘텐츠를 제거한 이미지에서 그 위치를 다른 콘텐츠로 대체하는 방법으로 이용할 수 있다.

### 2. 이론 설명

 우리는 도메인 B의 샘플 b를 A의 샘플 a로 전송한다. 또, 도메인별 콘텐츠의 시맨틱 세분화를 약하게 감독하는 작업도 고려한다. 즉, 도메인 A와 B의 샘플이 주어지면 도메인별 부분에 레이블을 지정하거나 분할 마스크를 지정한다.  또한, 속성 제거도 고려한다. 사진의 B에서 도메인의 특정 부분을 제거한다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-1.png?raw=true'>

**기본 이론**

 이 논문의 방법은 5개의 다른 네트워크로 구성된다.

1. Ec는 도메인 A와 B 사이의 공통 정보를 캡쳐하는 것을 목표로 한다.
2. 또 다른 인코더인 Es는 도메인 B에서 별도의 정보를 캡쳐하는 것을 목표로 한다.
3. 혼잡 네트워크 도메인 C는 두 도메인에 대해 Ec가 생성한 인코딩을 구별할 수 없도록 만드는데 이용된다.
4. 디코더인 DA는 공통 인코더 Ec에서 얻을 수 있는 표현이 주어지면 도메인 A에서 샘플을 생성한다. 해당 샘플이 B에서 온 경우, 도메인별 콘텐츠가 제거된다.
5. a와 b의 도메인별 콘텐츠를 결합하는 이미지 생성은 디코더 DB에 의해서 수행되며, DB는 두가지 이미지 크기 출력인 z raw와 m을 반환한다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-2.png?raw=true'>

 여기서 m(a,b)는 0과 1 사이의 값을 갖는 소프트 마스크이고 z raw는 이미지이다. 마스크와 생성된 이미지는 모두 배치 및 기타 모양 수정 사항을 결정하는 이미지 a뿐만 아니라 b에 의해서도 달라진다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-3.png?raw=true'>

 최종 출력 z는 이러한 출력 이미지 a의 조합이며 여기서 x는 요소별 곱셈을 나타낸다. 따라서 그림2는 추론 단계와 다섯개의 네트워크를 보여준다.

**도메인 혼잡 손실(Sa,Sb?)**
 우리는 Ec에서 생성된 공통 인코딩이 두 도메인 모두에 공통적인 정보만을 포함하도록 보장하려고 한다. 이는 재구성 손실을 도메인 혼잡 손실과 결합함으로써 이루어진다. 이 두 도메인의 인코딩이 통계적으로 일치하도록 장려하는 판별자 네트워크 C를 사용한다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-4.png?raw=true'>

 Sa 와 Sb가 두 도메인과 l(p, q) = −(q log(p) + (1 − q) log(1 − p))에서의 샘플 학습이 이루어지는 곳은 p ∈ [0, 1] and q ∈ {0, 1}의 이진 교차 엔트로피 손실이다. C는 구별할수 없는 인코딩을 Ec에서 생성하고자 하는 동안 C는 도메인 A와 B의 인코딩을 구별하려고 시도한다. Ec가 두 분포를 구별할 수 없도록 하는동안 C는 다음과 같은 목표를 최소화하기 위해 적대적 방식으로 훈련된다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-5.png?raw=true'>

**재구성 손실**
 도메인 혼동 손실은 공통 인코더인 Ec가 도메인 B에서 별도의 정보를 인코딩하지 않도록 합니다. 샘플 A의 경우 우리는 Ec(a)의 정보가 그것을 재구성하기에 충분한지 검증해야 하고, 도메인 A의 모든 정보가 Ec에 의해 인코딩 되는지 확인해야 한다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-6.png?raw=true'>

 여기서 II1은 RGB 이미지 값에 직접 적용되는 L1 손실이다. 비슷하게, Es에 의해 인코딩된 정보가 Es(b)가 도메인 B의 도메인별 정보를 포함하도록 별도의 세부 정보를 재구성하기에 충분한지 확인한다. 이미지 B가 주어지면 DA(Ec(b))를 사용하여 이미지에서 별도의 정보를 제거하고 다시 추가하여 이 작업을 수행한다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-7.png?raw=true'>

 우리는 z’을 z 대신에 이용하는데, 이는 Ec가 Da가 아닌 b에 직접적으로 적용되기 때문이다. 두 경우 모두 b의 공통 정보를 복구하지만 z를 사용하면 Da(Ec())를 통해 추가적인 에러를 검출한다. 다음은 z'의 정의이다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-8.png?raw=true'>

 마지막으로 우리는 마스크를 최소한으로 향상시킴으로써 두 도메인의 역할을 강화한다. 우리의 실험에서 우리는 마스크 크기를 명시적으로 제한하거나 다른 전통적인 정규화 용어를 사용하여 낮은 결과를 산출했다. 대신, 전송 파이프라인의 두 입력을 통해 각 도메인의 샘플을 실행하고 성공적인 재구성을 지향함으로써 보다 부드러운 방식으로 이 목표를 달성한다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-9.png?raw=true'>

 L(A,Recon2)은 z와 a 사이의 최소한의 거리를 권장한다. z raw는 a와 같은 것이 이상적이지만 완벽한 자동 인코딩을 할 수 없는 인코더와 디코더를 사용하기 때문에 z raw와 a 사이에는 약간의 거리가 있다. 따라서 z와 a 사이의 거리를 최소화하기 위해 네트워크는 마스크의 크기를 최소화해야한다. L(B,Recon2)도 같다.

**사이클 일관성 손실**
 잠재 공간에서의 사이클 일관성은 분리를 장려하기 위한 추가적인 제약으로 사용된다. LC를 최소화하기 위해 판별기 C를 별도로 훈련한다.  

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-10.png?raw=true'>

 II2는 MSE 손실이다. MSE(Mean Squared Error)는 손실함수로 오답에 가까울 수록 큰 값이 나온다.

**추론**
 일단 한 번 훈련되면, 네트워크는 감독되지 않은 콘텐츠 전송과 약하게 감독된 도메인별 정보의 세분화에 사용될 수 있다. 첫번째 경우, 우리는 a,b 에 대한 예제 z를 생성한다. 두번째로 도메인 B에서 두 입력 m(b,b)에 이미지 b를 공급하여 생성된 마스크를 고려한 다음 임계값을 적용하여 이진 마스크를 얻는다. 이 방법은 정확한 임계값에 거의 영향을 받지 않는다. 네트워크는 Zunmasked := DA(Ec(b))를 생성하여 특성 제거에 사용할 수도 있다. Zunmasked는 별도의 부분이 제거된 B로, 재구성된 얼굴 형상의 누락을 방지하기 위해 생성된 출력은 다음과 같이 계산된다.

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-11.png?raw=true'>

 M은 소프트 마스크 m의 이분 마스크이다. 

### 2-2. Experiments(평가)

 콘텐츠 전송, 도메인 외부 조작, 속성 제거, 순차 콘텐츠 전송, 순차 속성 제거 및 콘텐츠 추가, 도메인별 콘텐츠의 약한 감독 세분화에 대한 방법을 평가한다.

**콘텐츠 전송**
 셀럽 A 데이터세트에 미소, 수염, 안경 속성을 사용한다. A를 속성이 없는 이미지, B를 속성이 있는 이미지로 한다. 우리는 먼저 B의 별도 부분을 A의 공통 부분에 추가하는 능력을 고려한다. 기준 방법의 그림3과 비교하여 보다시피 안경의 국소 구조만 변경되는 반면, 기준선에서는 많은 세부사항이 손실되고 불필요한 변경이 이루어진다. 그림 1은 소스 이미지 a의 다른 방향을 수용하고 안경을 b에서 올바른 방향으로 조정할 수 있는 우리 방법의 능력을 보여준다.
 도메인 번역의 품질을 평가하기 위해 몇 가지 정량적 평가를 실시한다. 표1에서 생성된 이미지의 품질과 다양성을 평가하는데 일반적으로 사용되는 지표인 FID, FID에 대한 대안으로 제안된 KID로 상대적으로 평가한다. 보다시피 우리의 방법은 높은 점수를 받는다.
 우리는 b의 별도 부분을 타겟 이미지로 전송하는 우리 방법의 능력도 고려한다. 이를 위해 사전 훈련된 분류기를 사용하여 도메인 A와 B를 구별하고 변환된 이미지의 점수를 고려한다. 이는 표2에 보고되어있으며 분명한 이점을 보여준다. 소스ID가 보존되는지 평가하기 위해 우리는 사전 훈련된 vgg 페이스 네트워크의 코사인 유사성을 계산한다. 높은 값은 보존된 ID를 나타낸다. 표3은 우리 결과가 소스 이미지와 훨씬 더 나은 유사성을 보인다는 것을 나타낸다.

**사용자 연구**
 사용자 연구 평가를 더욱 강화하기 위해 사용자 연구를 실시한다. 우리는 a와 b에서 20개의 이미지를 무작위로 샘플링하고 번역된 이미지와 기존의 이미지를 고려한다. 1) 사용자가 B의 분포와 더 가깝게 일치하는 번역된 이미지, 2) 번역된 이미지인 가이드 이미지 b가 주어지면 b의 분리된 부분이 더 잘 전송되고 3) a가 주어지면 세 가지 실험을 수행한다. 평균 점수는 표4에 나와있다. 수염과 안경의 경우 기준 방법보다 지속적으로 높은 점수를 받는다. 미소의 경우 사실적인 연출 능력이 약간 더 높으며, 미소를 원본 이미지에 전달하는 능력은 약간 나쁜 반면, 원본 이미지의 정체성을 보존하는 능력은 훨씬 높다.

**도메인 조작 능력**
 도메인 조작 중 학습된 모델이 도메인 이동을 처리할 수 있는 능력, 즉 훈련 중에는 볼 수 없었던 도메인으로부터의 변환을 수행할 수 있는 능력도 고려한다. 예를 들어, 우리는 안경을 쓰지 않은 여성의 얼굴을 도메인 A로 훈련하고, 안경을 쓴 여성의 얼굴을 도메인 B로 훈련한다. 테스트 시간에 A는 남성 얼굴의 도메인 A of로 대체되고, 우리는 우리가 기차나 테스트 샘플을 볼 수 없는 도메인 B from를 생성하면서 남성의 얼굴로 안경을 전달하도록 요청 받는다. 정량적 평가는 표 3에 제공되는데, 이는 우리 방법의 품질에서 무시해도 될 정도의 차이를 보여주며, 기준 방법의 경우 상당한 차이를 보여준다. 시각적 결과는 부록 C에서 찾을 수 있으며, 뿐만 아니라 도메인 이미지에서 극도로 벗어난 것도 우리 방법이 성공적으로 처리한다.

**핸드백 실험**
 핸드백의 손잡이가 다른 도메인 이미지의 핸드백에 맞추어 명확하게 적용된다.

**속성 제거**
 우리의 방법은 속성 전공 방법보다 더 일반적이지만, 그림6처럼 속성을 제거하는데 사용할 수 있다. 이 방법은 모든 기본 방법에 비해 생성 품질이 월등히 우수하며 충실도와 변환 사이의 절충점을 제시한다.

**순차적 콘텐츠 전송**
 우리의 방법을 순차적으로 적용하여 다른 가이드 이미지 및 다른 도메인의 안내된 콘텐츠를 순차적으로 추가할 수 있다. 이 방법은 기준을 훨씬 능가한다.

**속성 제거와 콘텐츠 추가**
 특정 속성을 제거하는 우리 방법에서 주어진 도메인 A와 B 간에 각각 도메인별 정보를 구분하여 안내된 콘텐츠 전송을 수행할 수 있다. 먼저 도메인 A의 도메인별 특성을 제거한 후 도메인 B에 대한 안내 콘텐츠 추가를 수행한다. 얼굴 특징을 낭비적으로 재구성하지 않으므로 기준을 크게 능가한다.

**약한 지도 분할**
 여성과 남성의 머리카락을 분할하는 작업에서 남성의 경우 A는 대머리, B는 어두운 머리의 남성으로 구성되어 있고, 여성의 경우 A는 금발, B는 흑발 여성으로 구성되어 있다. 우리는 보르자 등에 주어진 레이블을 사용하여 우리의 방법을 평가한다. 기준은 불필요한 디테일로 파손된 머리카락을 산출한다. 우리의 방법은 네트워크가 B를 재구성하기 위해 올바른 위치에 별도의 콘텐츠를 최소한으로 추가하도록 하였기 때문에 성능이 좋다.

*절제분석(표7)*
 L(B,Recon1), L(A,Recon1)이 없으면 마스크는 비어있기 때문에 수염이 이미지로 전송되지 않는다. LDC가 없으면 생성된 마스크는 탈착이 불가능하기 때문에 비어있다. LCycle이 없으면 생성된 마스크는 얼굴의 더 큰 부분을 포함하는데, 이는 유사성은 유지하지만 분류 점수를 손상시킨다. L(B,Recon2)가 없으면 마스크가 덜 부드러워지고, L(A,Recon2)가 없으면 특정과 다른 물체를 포착한다.
 L(A,Recon2)와 L(B,Recon2)는 콘텐츠를 인식하는 z에 의존하는 반면 L2는 콘텐츠에 관계없이 모두 동등하게 평가한다(표7).

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-12.png?raw=true'>

### 3. 모델 설명

<img src='https://github.com/HwanGonJang/HwanGonJang.github.io/blob/master/Pictures/ai_1-13.png?raw=true'>

 이 논문에서 소개하는 모델은 두 도메인 이미지에서 A 도메인에서는 특징(콘텐츠)를 추출하여 B 도메인에 삽입하는 모델이다. 기존의 비슷한 모델과 논문들이 존재하나 이 논문에서는 특별한 전략으로 모델 구현에 접근하여 기존 모델 대비 월등한 성능을 갖고 있다는 것이 특징이다. 이 논문에서 소개하는 모델의 접근 개념은 다음과 같다.
 먼저 두 이미지 간에 콘텐츠를 전송할 때 무엇을 어디로 전송해야 하는지, 어떻게 전송해야 하는지 알아야 한다. 이전의 작업은 글로벌 스타일 특성을 이전하거나 '어디' 측면을 무시해 결과적으로 집중이 부족한 비효율적인 세대를 초래한다. 우리의 작업에서는 "무엇"의 측면은 E가 포착하고, DB는 "어디"와 "어떻게"를 모두 포착한다. 우리의 결과는 콘텐츠가 배치된 상황에서 삽입된 콘텐츠의 위치뿐만 아니라 표시되는 형태도 결정한다는 것을 보여준다. 여기서 두 가지 측면은 고정된 콘텐츠 가이드 이미지 b에서도 적용된다. 안내된 콘텐츠 전송 문제에 대한 포괄적인 모델링은 현재 최신 기술보다 훨씬 우수한 결과로 이어진다. 또한 "where"의 모델링을 통해 약한 지도 방식으로 정확한 분할 마스크를 획득하고, 콘텐츠를 제거하고, 이미지 간에 콘텐츠를 교환하며, 점진적인 품질 저하 없이 여러 콘텐츠를 추가할 수 있다.